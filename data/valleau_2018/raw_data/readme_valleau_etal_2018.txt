
1. Reference:
Valleau, M. J., Konishi, H., Golinkoff, R. M., Hirsh-Pasek, K., & Arunachalam, S. (2018). An eye-tracking study of receptive verb knowledge in toddlers. Journal of speech, language, and hearing research, 61(12), 2917-2933.

2. Abstract
This study aimed to examine receptive verb knowledge in 22- to 24-month-old toddlers using a dynamic video eye-tracking test. The primary goal was to explore the suitability of eye-gaze measures for studying verb knowledge compared to noun knowledge. The results showed that eye-gaze measures, such as an increase in looking time to the target video from a baseline phase to the test phase, correlated with scores on the MacArthur-Bates Communicative Development Inventories (CDI). However, these measures operated differently for verbs compared to nouns. Overall, the findings suggest that the dynamic nature of videos depicting verb knowledge results in differences in eye-gaze patterns compared to static images depicting nouns. This highlights the need for the development of an eye-tracking assessment specifically designed for verb knowledge. The specific measures used in such assessments may differ from those used for static images and nouns.

3. Importing decisions
1)the original data contains baseline and response subphases (no data for the query). We only used the data for the response subphase. The data starts from 300ms of the response subphase, which is also the disambiguation point

2) the original data does not have columns for the target picture and target side. The authors shared the experiment videos with us, so we got the target picture and target side information from the video and saved the information in the file "stimuli_lookup_table.

3)There are four types of coded values for elegize: target look, distractor, trackloss and other(which are generated by eye-trackers when the children's gazes were captured but they are not looking at the target or the distractor

4)ToDo: The figure in the paper shows that at the start of the data (300ms), the average proportion of target look is above 0.5. However, in the data, the proportion of targets looking at 300ms is close to 0. Need to figure out why.

5. Original study info
Carrier phrases: "The audio for noun trials consisted of simple carrier phrases (e.g., "Where is the cookie!"), whereas for verb trials, it varied by whether the depicted event involved one or two participants; one-participant events were queried with intransitive syntax (e.g., "Where is she clapping?"), and two-participant events were queried with transitive syntax (e.g., "Where is she bouncing the ball?"). The carrier frames varied in this way because we used what we thought was the most discourse-natural query for the different event types. For both event types, we also included queries in neutral syntax (e.g., "Find clapping!")."

Trial structure: still images (noun trials) or dynamic videos (verb trials) appeared on the screen during the Salience phase, then disappeared with a central fixation star and the test query (e.g., where is the ...); the images or videos reappeared during the Response phase

Timing of target word: between the Salience and Response phases (i.e., the query occurred once just before the onset of the Response phase; it occurred again partway through the Response phase)

Order of trials for the forward orders:
Cookie-Banana
Goldfish-Doughnut
Firetruck-Bird
Feed-Hug
Pour-Drink
Wash-Rock
Cut-Tie
Crab-Pancakes
Eat-Push
Run-Jump
Shake-Open
Read-Rip
Rocketship-Giraffe
Stretch-Clap
Roll-Bounce
Lift-Pul
March-Spin
Squirrel-Grapes
Dance-Cry
Drop-Bite
Kiss-Tickle
Squeeze-Blow
Orange-Airplane
Kick-Throw
Lick-Break

Order of trials for the backward orders:
Orange-Airplane
Squirrel-Grapes
Rocketship-Giraffe
Lick-Break
Kick-Throw
Squeeze-Blow
Kiss-Tickle
Crab-Pancakes
Drop-Bite
Dance-Cry
March-Spin
Lift-Pul
Firetruck-Bird
Roll-Bounce
Stretch-Clap
Read-Rip
Shake-Open
Goldfish-Doughnut
Run-Jump
Eat-Push
Cut-Tie
Wash-Rock
Cookie-Banana
Pour-Drink
Feed-Hug


